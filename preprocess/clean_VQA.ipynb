{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_loaders.VQA import VQADataset\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 440014/440014 [00:02<00:00, 200256.80it/s]\n",
      "440014it [00:23, 18696.32it/s]\n"
     ]
    }
   ],
   "source": [
    "annotation_path='/home/hallscope/data/VQA/v2_train.json'\n",
    "img_root='/root/autodl-fs/coco_images/train'\n",
    "split='train'\n",
    "with open(annotation_path, 'r') as file:\n",
    "    ann = json.load(file)\n",
    "\n",
    "data = []\n",
    "with open(annotation_path, 'r') as file:\n",
    "    ann = json.load(file)\n",
    "data_cat = [\n",
    "    {\n",
    "        \"img_path\": os.path.join(img_root, f\"COCO_{split}2014_{ins['image_id']:012}.jpg\"),\n",
    "        \"question\": f\"{ins['question']}\\nAnswer the question using a single word or phrase.\\n\",\n",
    "        \"answers\": ins['answers'],\n",
    "        \"question_id\": ins[\"question_id\"]\n",
    "    }\n",
    "    for ins in tqdm(ann)\n",
    "]\n",
    "data += data_cat\n",
    "\n",
    "kept_ann=[]\n",
    "for i,ins in tqdm(enumerate(data)):\n",
    "    if os.path.exists(ins['img_path']):\n",
    "        kept_ann.append(ann[i])\n",
    "\n",
    "with open(annotation_path, 'w') as file: \n",
    "    json.dump(kept_ann, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

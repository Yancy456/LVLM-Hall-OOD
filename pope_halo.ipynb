{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from utils.store_data import ReadData\n",
    "import numpy as np\n",
    "from llm.prompt_loader import PromptLoader\n",
    "import torch\n",
    "from utils.arguments import Arguments\n",
    "from tqdm import tqdm\n",
    "from llm.ml_tools import svd_embed_score\n",
    "from sklearn.decomposition import PCA\n",
    "from metric_utils import get_measures, print_measures\n",
    "from linear_probe import get_linear_acc\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path': '/root/autodl-fs/coco_images/val/COCO_val2014_000000310196.jpg',\n",
       " 'question': 'Is there a snowboard in the image?\\nAnswer the question using a single word or phrase.',\n",
       " 'label': 1,\n",
       " 'question_id': 1,\n",
       " 'category': 'popular',\n",
       " 'most_likely': {'embedding': array([[[ 3.8909912e-03,  1.4953613e-03,  5.4626465e-03, ...,\n",
       "           -4.2114258e-03,  1.5075684e-02,  2.4261475e-03]],\n",
       "  \n",
       "         [[-5.3787231e-03, -1.2474060e-03,  8.8424683e-03, ...,\n",
       "           -1.1787415e-02,  8.6975098e-03,  9.3383789e-03]],\n",
       "  \n",
       "         [[-3.2531738e-02,  3.3264160e-03,  1.9363403e-02, ...,\n",
       "            8.7356567e-03,  2.6062012e-02,  9.3231201e-03]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 1.5664062e+00,  2.2695312e+00, -4.0673828e-01, ...,\n",
       "           -2.7734375e+00, -1.3789062e+00, -2.1718750e+00]],\n",
       "  \n",
       "         [[ 2.2363281e+00,  2.5859375e+00, -5.2978516e-01, ...,\n",
       "           -2.6347656e+00, -1.5664062e+00, -2.3593750e+00]],\n",
       "  \n",
       "         [[ 8.9501953e-01,  3.9526367e-01,  9.9853516e-01, ...,\n",
       "           -5.2783203e-01,  3.5180664e-01, -1.5263672e+00]]], dtype=float32),\n",
       "  'response': 'yes'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reader=ReadData('/home/hallscope/output/pope')\n",
    "data=data_reader.read_all()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "      <th>question_id</th>\n",
       "      <th>category</th>\n",
       "      <th>most_likely</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/root/autodl-fs/coco_images/val/COCO_val2014_0...</td>\n",
       "      <td>Is there a snowboard in the image?\\nAnswer the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>popular</td>\n",
       "      <td>{'embedding': [[[ 0.00389099  0.00149536  0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/root/autodl-fs/coco_images/val/COCO_val2014_0...</td>\n",
       "      <td>Is there a dining table in the image?\\nAnswer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>popular</td>\n",
       "      <td>{'embedding': [[[ 0.00389099  0.00149536  0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/root/autodl-fs/coco_images/val/COCO_val2014_0...</td>\n",
       "      <td>Is there a person in the image?\\nAnswer the qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>popular</td>\n",
       "      <td>{'embedding': [[[ 0.00389099  0.00149536  0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/root/autodl-fs/coco_images/val/COCO_val2014_0...</td>\n",
       "      <td>Is there a car in the image?\\nAnswer the quest...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>popular</td>\n",
       "      <td>{'embedding': [[[ 0.00389099  0.00149536  0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/root/autodl-fs/coco_images/val/COCO_val2014_0...</td>\n",
       "      <td>Is there a skis in the image?\\nAnswer the ques...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>popular</td>\n",
       "      <td>{'embedding': [[[ 0.00389099  0.00149536  0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  \\\n",
       "0  /root/autodl-fs/coco_images/val/COCO_val2014_0...   \n",
       "1  /root/autodl-fs/coco_images/val/COCO_val2014_0...   \n",
       "2  /root/autodl-fs/coco_images/val/COCO_val2014_0...   \n",
       "3  /root/autodl-fs/coco_images/val/COCO_val2014_0...   \n",
       "4  /root/autodl-fs/coco_images/val/COCO_val2014_0...   \n",
       "\n",
       "                                            question  label  question_id  \\\n",
       "0  Is there a snowboard in the image?\\nAnswer the...      1            1   \n",
       "1  Is there a dining table in the image?\\nAnswer ...      0            2   \n",
       "2  Is there a person in the image?\\nAnswer the qu...      1            3   \n",
       "3  Is there a car in the image?\\nAnswer the quest...      0            4   \n",
       "4  Is there a skis in the image?\\nAnswer the ques...      1            5   \n",
       "\n",
       "  category                                        most_likely  \n",
       "0  popular  {'embedding': [[[ 0.00389099  0.00149536  0.00...  \n",
       "1  popular  {'embedding': [[[ 0.00389099  0.00149536  0.00...  \n",
       "2  popular  {'embedding': [[[ 0.00389099  0.00149536  0.00...  \n",
       "3  popular  {'embedding': [[[ 0.00389099  0.00149536  0.00...  \n",
       "4  popular  {'embedding': [[[ 0.00389099  0.00149536  0.00...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_label=df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset length:2400\n",
      "validset length:300\n",
      "testset length:300\n",
      "trainset postive: 1210 negative: 1190\n",
      "testset postive: 147 negative: 153\n"
     ]
    }
   ],
   "source": [
    "length=len(data)\n",
    "wild_ratio=0.9\n",
    "\n",
    "all_indices = np.random.permutation(length)\n",
    "train_val_idxs = all_indices[:int(\n",
    "    wild_ratio * length)]  # trainset and validation index\n",
    "\n",
    "test_idxs=all_indices[int(\n",
    "    wild_ratio * length):]  #test index\n",
    "\n",
    "validset_len = 300\n",
    "# exclude validation samples.\n",
    "train_idxs = train_val_idxs[:len(\n",
    "    train_val_idxs) - validset_len]  # trainset index\n",
    "val_idxs = train_val_idxs[len(\n",
    "    train_val_idxs) - validset_len:]  # validation index\n",
    "gt_label_test = []\n",
    "gt_label_wild = []\n",
    "gt_label_val = []\n",
    "\n",
    "for i in range(length):\n",
    "    if i not in train_val_idxs:\n",
    "        gt_label_test.extend(gt_label[i: i+1])\n",
    "    elif i in train_idxs:\n",
    "        gt_label_wild.extend(gt_label[i: i+1])\n",
    "    else:\n",
    "        gt_label_val.extend(gt_label[i: i+1])\n",
    "\n",
    "'''get testset, wildset and valset. The valset is used for determining the hype-parameters'''\n",
    "gt_label_test = np.asarray(gt_label_test)\n",
    "gt_label_wild = np.asarray(gt_label_wild)\n",
    "gt_label_val = np.asarray(gt_label_val)\n",
    "\n",
    "print(f'trainset length:{len(gt_label_wild)}')\n",
    "print(f'validset length:{len(gt_label_val)}')\n",
    "print(f'testset length:{len(gt_label_test)}')\n",
    "print(f'trainset postive: {sum(gt_label_wild==1)} negative: {sum(gt_label_wild==0)}')\n",
    "print(\n",
    "    f'testset postive: {sum(gt_label_test==1)} negative: {sum(gt_label_test==0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 33, 4096)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_generated = df['most_likely'].apply(lambda x: np.squeeze(x['embedding'])).to_list()\n",
    "embed_generated =np.stack(embed_generated)\n",
    "embed_generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_indices_wild = []\n",
    "feat_indices_eval = []\n",
    "\n",
    "for i in range(length):\n",
    "    if i in train_idxs:\n",
    "        feat_indices_wild.extend(np.arange(i, i+1).tolist())\n",
    "    elif i in val_idxs:\n",
    "        feat_indices_eval.extend(np.arange(i, i + 1).tolist())\n",
    "embed_generated_wild = embed_generated[feat_indices_wild][:, 1:, :]\n",
    "embed_generated_eval = embed_generated[feat_indices_eval][:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:06,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1 AUROC:78.8027259364839 layer:  30 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:01<00:06,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  2 AUROC:85.28350630261457 layer:  28 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:02<00:05,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  3 AUROC:94.4055944055944 layer:  28 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:03<00:05,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  4 AUROC:94.5124938755512 layer:  31 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:04<00:04,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  5 AUROC:94.39668611643134 layer:  28 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:04<00:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  6 AUROC:94.3120573693822 layer:  28 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:05<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  7 AUROC:94.34769052603447 layer:  28 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:06<00:01,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  8 AUROC:94.21852033317 layer:  28 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:07<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  9 AUROC:93.99135895951181 layer:  23 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  10 AUROC:93.94236336911497 layer:  23 mean:  0 svd:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tdirect-projection\n",
      "  FPR95 AUROC AUPR\n",
      "& 32.68 & 93.86 & 95.39\n"
     ]
    }
   ],
   "source": [
    "# k_span is the max k value\n",
    "# graid search for best hyper-parameters on validation set, and store them into returned_results\n",
    "weighted_svd=True\n",
    "returned_results = svd_embed_score(embed_generated_eval, gt_label_val,\n",
    "                                   begin_k=1, k_span=11, mean=0, svd=0, weight=weighted_svd)\n",
    "\n",
    "pca_model = PCA(n_components=returned_results['k'], whiten=False).fit(\n",
    "    embed_generated_wild[:, returned_results['best_layer'], :])\n",
    "projection = pca_model.components_.T\n",
    "if weighted_svd:\n",
    "    projection = pca_model.singular_values_ * projection\n",
    "scores = np.mean(np.matmul(\n",
    "    embed_generated_wild[:, returned_results['best_layer'], :], projection), -1, keepdims=True)\n",
    "assert scores.shape[1] == 1\n",
    "best_scores = np.sqrt(np.sum(np.square(scores), axis=1)\n",
    "                      ) * returned_results['best_sign']\n",
    "\n",
    "'''get score for direct projection'''\n",
    "# direct projection\n",
    "\n",
    "feat_indices_test = []\n",
    "for i in range(length):\n",
    "    if i not in train_val_idxs:\n",
    "        feat_indices_test.extend(np.arange(1 * i, 1 * i + 1).tolist())\n",
    "\n",
    "embed_generated_test = embed_generated[feat_indices_test][:, 1:, :]\n",
    "\n",
    "test_scores = np.mean(np.matmul(embed_generated_test[:, returned_results['best_layer'], :],\n",
    "                                projection), -1, keepdims=True)\n",
    "\n",
    "assert test_scores.shape[1] == 1\n",
    "test_scores = np.sqrt(np.sum(np.square(test_scores), axis=1))\n",
    "\n",
    "measures = get_measures(returned_results['best_sign'] * test_scores[gt_label_test == 1],\n",
    "                        returned_results['best_sign'] * test_scores[gt_label_test == 0], plot=False)\n",
    "print_measures(measures[0], measures[1], measures[2], 'direct-projection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score distributes in range: 105415.8984375-3.81640625\n"
     ]
    }
   ],
   "source": [
    "print(f'best_score distributes in range: {best_scores.max()}-{best_scores.min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_indices_test = []\n",
    "for i in range(length):\n",
    "    if i not in train_val_idxs:\n",
    "        feat_indices_test.extend(np.arange(1 * i, 1 * i + 1).tolist())\n",
    "\n",
    "embed_generated_test = embed_generated[feat_indices_test][:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/38 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n",
      "postive: 2338 negative: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/38 [01:21<50:13, 81.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thres:  976.6416 best result:  [np.float64(95.01133786848072)] best_layer:  11 best_accuracy 0.8733333333333333 linear best_threshold 0.9832486\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n",
      "postive: 2276 negative: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/38 [01:51<1:08:44, 111.48s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# gt training, saplma\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# embed_train = embed_generated_wild[:,layer,:]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# label_train = gt_label_wild\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# gt training, saplma\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostive: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(label_train\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m negative: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(label_train\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m best_acc, final_acc, (\n\u001b[0;32m---> 25\u001b[0m     clf, best_state, best_preds, preds, labels_val), losses_train \u001b[38;5;241m=\u001b[39m \u001b[43mget_linear_acc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_ret\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcosine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnonlinear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0003\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m clf\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     39\u001b[0m output \u001b[38;5;241m=\u001b[39m clf(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\n\u001b[1;32m     40\u001b[0m     embed_generated_test[:, layer, :])\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcuda())\n",
      "File \u001b[0;32m/home/hallscope/linear_probe.py:295\u001b[0m, in \u001b[0;36mget_linear_acc\u001b[0;34m(ftrain, ltrain, ftest, ltest, n_cls, epochs, args, classifier, print_ret, normed, nonlinear, learning_rate, weight_decay, batch_size, cosine, lr_decay_epochs)\u001b[0m\n\u001b[1;32m    292\u001b[0m loss_train, acc \u001b[38;5;241m=\u001b[39m train(train_loader, classifier, criterion, optimizer, epoch, print_freq\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mprint_freq)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# eval for one epoch\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m loss, val_acc, preds, labels_out \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_freq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m best_acc:\n\u001b[1;32m    297\u001b[0m     best_acc \u001b[38;5;241m=\u001b[39m val_acc\n",
      "File \u001b[0;32m/home/hallscope/linear_probe.py:202\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(val_loader, classifier, criterion, print_freq)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    201\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (features, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_loader):\n\u001b[1;32m    203\u001b[0m         features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    204\u001b[0m         labels_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(labels_out, labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:697\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl3.9/lib/python3.9/site-packages/torch/autograd/profiler.py:733\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl3.9/lib/python3.9/site-packages/torch/_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "thresholds = np.linspace(0, 1, num=40)[1:-1]\n",
    "\n",
    "# graid search\n",
    "auroc_over_thres = []\n",
    "for thres_wild in tqdm(thresholds):\n",
    "    best_auroc = 0\n",
    "    best_accuracy=0\n",
    "    for layer in range(len(embed_generated_wild[0])):\n",
    "        thres_wild_score = np.sort(best_scores)[\n",
    "            int(len(best_scores) * thres_wild)]\n",
    "        true_wild = embed_generated_wild[:, layer,:][best_scores > thres_wild_score]\n",
    "        false_wild = embed_generated_wild[:, layer,:][best_scores <= thres_wild_score]\n",
    "\n",
    "        embed_train = np.concatenate([true_wild, false_wild], 0) # true label: 1; false label:0\n",
    "        label_train = np.concatenate([np.ones(len(true_wild)),\n",
    "                                      np.zeros(len(false_wild))], 0)\n",
    "\n",
    "        # gt training, saplma\n",
    "        # embed_train = embed_generated_wild[:,layer,:]\n",
    "        # label_train = gt_label_wild\n",
    "        # gt training, saplma\n",
    "        print(f'postive: {sum(label_train==1)} negative: {sum(label_train==0)}')\n",
    "\n",
    "        best_acc, final_acc, (\n",
    "            clf, best_state, best_preds, preds, labels_val), losses_train = get_linear_acc(\n",
    "            embed_train,\n",
    "            label_train,\n",
    "            embed_train,\n",
    "            label_train,\n",
    "            2, epochs=50,\n",
    "            print_ret=True,\n",
    "            batch_size=512,\n",
    "            cosine=True,\n",
    "            nonlinear=True,\n",
    "            learning_rate=0.05,\n",
    "            weight_decay=0.0003)\n",
    "\n",
    "        clf.eval()\n",
    "        output = clf(torch.from_numpy(\n",
    "            embed_generated_test[:, layer, :]).to(torch.float32).cuda())\n",
    "        pca_wild_score_binary_cls = torch.sigmoid(output)\n",
    "\n",
    "        pca_wild_score_binary_cls = pca_wild_score_binary_cls.cpu().data.numpy()\n",
    "\n",
    "        #pred_labels=(pca_wild_score_binary_cls >= 0.5).astype(int)\n",
    "        \n",
    "        #pred_acc=accuracy_score(gt_label_test,pred_labels)\n",
    "\n",
    "        if np.isnan(pca_wild_score_binary_cls).sum() > 0:\n",
    "            breakpoint()\n",
    "        measures = get_measures(pca_wild_score_binary_cls[gt_label_test == 1],\n",
    "                                pca_wild_score_binary_cls[gt_label_test == 0], plot=False)\n",
    "        \n",
    "        #auroc=roc_auc_score(gt_label_test,pca_wild_score_binary_cls)\n",
    "        #if auroc> best_auroc:\n",
    "        #    best_auroc=auroc\n",
    "        #    best_accuracy=pred_acc\n",
    "        #    best_layer=layer\n",
    "\n",
    "        #if pred_acc> best_accuracy:\n",
    "        #    best_accuracy=pred_acc\n",
    "        \n",
    "        \n",
    "        if measures[0] > best_auroc:\n",
    "            best_auroc = measures[0]\n",
    "            best_result = [100 * measures[0]]\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(gt_label_test,pca_wild_score_binary_cls)\n",
    "\n",
    "            # Calculate Youden's J statistic\n",
    "            youdens_j = tpr - fpr\n",
    "            # Find the index of the maximum J statistic \n",
    "            best_index = np.argmax(youdens_j) \n",
    "            best_threshold = thresholds[best_index]\n",
    "\n",
    "            pred_labels=(pca_wild_score_binary_cls >= best_threshold).astype(int)\n",
    "            best_accuracy=accuracy_score(gt_label_test,pred_labels)\n",
    "\n",
    "            best_layer = layer\n",
    "\n",
    "\n",
    "    print('thres: ', np.sort(best_scores)[\n",
    "            int(len(best_scores) * thres_wild)], 'best result: ',\n",
    "          best_result, 'best_layer: ', best_layer,'best_accuracy',best_accuracy,'linear best_threshold',best_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
